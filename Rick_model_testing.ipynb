{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple Sentiment on Twitter: 2013 vs 2023\n",
    "By Sarah Prusaitis, Rick Lataille, and Allison Ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- 2013 SXSW festival was a big success, very positive responses to new products\n",
    "- What was the nature of that positive response, what did people like\n",
    "- 10 years later, what is the public's response to Apple's new products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "- Has Apple maintained the public's support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Limitations\n",
    "- language shifts over time\n",
    "- dataset only includes pos/neg, no neutral examples\n",
    "- working with limited vocabulary, more robust approach would train on larger dataset\n",
    "- pos/neg sentiment may reflect not just apple, but tech in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- Using 2013 dataset, tagged positive or negative by human raters\n",
    "    - Also including 10% of more recent tweets, labeled with VADER, to broaden vocabulary\n",
    "- Applying fitted models to new Vision Pro datasets to determine sentiment balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I ADDED PACKAGES IN THE NEXT CELL<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "import langid\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, regexp_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read original data\n",
    "df1 = pd.read_csv('data/judge-1377884607_tweet_product_company.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read synthetic data\n",
    "df2 = pd.read_csv('data/Apple_Product_Negative_ Tweets_Sheet1.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I ADDED THE NEXT SEVERAL CELLS<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Vision Pro data\n",
    "df_vp = pd.read_csv('data/vision_pro_sentiment.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    usecols=['tweetText', 'mark']\n",
    "                   ).rename(columns={'tweetText': 'tweet', 'mark':'sentiment'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "- Converting emoticons to unique strings\n",
    "- Removing semantically meaningless patterns (mentions, links, etc)\n",
    "- Adding limited additional stopwords that likely have no semantic meaning\n",
    "- Tokenization, POS-tagging and Lemmatization\n",
    "- TF-IDF Vectorization and Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only English-language tweets, then drop language column\n",
    "df_vp['language'] = df_vp['tweet'].apply(lambda x: langid.classify(x)[0])\n",
    "df_english = df_vp.loc[df_vp['language']=='en'].drop('language',axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10% of Vision Pro tweets for training purposes\n",
    "df_english_train = df_english.sample(n=round(len(df_vp)*.1))\n",
    "df_english.drop(df_english_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Vision Pro labels to 1, 0\n",
    "convert = {'Positive emotion':1, 'Negative emotion':0}\n",
    "df_english['sentiment'] = df_english['sentiment'].map(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for simplicity\n",
    "df1 = df1.rename(columns = {'tweet_text': 'tweet', \n",
    "                         'emotion_in_tweet_is_directed_at': 'product', \n",
    "                         'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine rows into a single DataFrame\n",
    "df = pd.concat([df1, df2], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined and renamed Apple products and non Apple products \n",
    "\n",
    "df['product'] = df['product'].replace({\n",
    "    'iPad': 'Apple',\n",
    "    'Apple': 'Apple',\n",
    "    'iPad or iPhone App': 'Apple',\n",
    "    'iPhone': 'Apple',\n",
    "    'Other Apple product or service': 'Apple',\n",
    "    'Google': 'Other',\n",
    "    'Other Google product or service': 'Other',\n",
    "    'Android App': 'Other',\n",
    "    'Android': 'Other'\n",
    "})\n",
    "#there are 5802 rows that are null - what should we do with those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I THINK I MOVED THIS UP IN ORDER TO DROP AS MANY TWEETS AS EARLY AS POSSIBLE (MAKES SUBSEQUENT CODE RUN FASTER)<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for only Apple tweets, and drop 'product column'\n",
    "df_apple = df[df['product']=='Apple'].drop('product',axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in Vision Pro tweets\n",
    "df_apple = pd.concat([df_apple, df_english_train], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate no emotion entries, and drop\n",
    "df_apple['sentiment'] = df_apple['sentiment'].replace(\"I can't tell\", \"No emotion toward brand or product\")\n",
    "df_apple = df_apple.drop(df_apple[df_apple['sentiment'] == 'No emotion toward brand or product'].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple['tweet'] = df_apple['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emoticons(text):\n",
    "    # Define a dictionary mapping emoticons to their corresponding meanings\n",
    "    emoticon_mapping = {\n",
    "        ':D': 'emojismile',\n",
    "        ':)': 'emojismile',\n",
    "        ':-D': 'emojismile',\n",
    "        ':\\'': 'emojiunsure',\n",
    "        ':p': 'emojitongue',\n",
    "        ':P': 'emojitongue',\n",
    "        ':(': 'emojisad'\n",
    "        # Add more emoticons and their meanings as needed\n",
    "    }\n",
    "    pattern = re.compile('|'.join(re.escape(emoticon) for emoticon in emoticon_mapping.keys()))\n",
    "    \n",
    "    def replace(match):\n",
    "        return emoticon_mapping[match.group(0)]\n",
    "\n",
    "    return pattern.sub(replace, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I ADDED A LINE BELOW<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace emoticons with mapped strings\n",
    "df_apple['tweet'] = df_apple['tweet'].apply(replace_emoticons)\n",
    "df_english['tweet'] = df_english['tweet'].apply(replace_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # Remove links and mentions\n",
    "    tweet = re.sub(r'http\\S+|@\\S+', '', tweet)\n",
    "    \n",
    "    # Remove {link}\n",
    "    tweet = re.sub(r'\\{link\\}', '', tweet)\n",
    "    \n",
    "    # Replace &quot; with \"\n",
    "    tweet = tweet.replace('&quot;', '\"')\n",
    "    \n",
    "    # Remove extra space between quotation mark and words\n",
    "    tweet = re.sub(r'\\s+\"', '\"', tweet)\n",
    "    tweet = re.sub(r'\"\\s+', '\"', tweet)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'([^\\w\\s]|_)+', ' ', tweet)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    \n",
    "    # Part-of-speech tagging\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = []\n",
    "    for word, pos in tagged_tokens:\n",
    "        if pos.startswith('J'):\n",
    "            pos = 'a'  # Adjective\n",
    "        elif pos.startswith('V'):\n",
    "            pos = 'v'  # Verb\n",
    "        elif pos.startswith('N'):\n",
    "            pos = 'n'  # Noun\n",
    "        elif pos.startswith('R'):\n",
    "            pos = 'r'  # Adverb\n",
    "        else:\n",
    "            pos = 'n'  # Default to noun\n",
    "        lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    \n",
    "    # Add additional stopwords\n",
    "    additional_stopwords = {'w', 'u', 'amp', 'sxsw', 'rt'}  # amp = & \n",
    "    additional_stopwords.update('apple', 'sxswi', 'ipad', 'iphone')\n",
    "    stop_words = set(stopwords.words('english')) | additional_stopwords\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tweet = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I ADDED A LINE BELOW<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all tweets\n",
    "df_apple['tweet'] = df_apple['tweet'].astype(str).apply(preprocess_tweet)\n",
    "df_english['tweet'] = df_english['tweet'].astype(str).apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label target with 1's and 0's\n",
    "df_apple['target'] = df_apple['sentiment'].map({'Positive emotion': 1, 'Negative emotion': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = df_apple['tweet']\n",
    "y = df_apple['target'] # Target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized data for Doc2Vec vectorizer\n",
    "tokenized_train_data = X_train\n",
    "tokenized_test_data = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized tweets back into strings for TfidfVectorizer\n",
    "X_train_str = X_train.apply(lambda x: ' '.join(x))\n",
    "X_test_str = X_test.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization\n",
    "- Most common approach, more meaning than simple bag-of-words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I CHANGED SOME OF THE INSTANTIATION ARGUMENTS<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=3, ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform the vectorizer on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_str)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: THIS CELL IS NEW, IT'S NEEDED IN ORDER TO RESTRICT VOCAB ON VISION PRO DATA<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocab for vision pro analysis and retrain\n",
    "vocab = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,2), vocabulary=vocab)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_str)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec Vectorization\n",
    "- This is a more sophisticated approach, captures additional meaning from document and word context\n",
    "- GBM models can make use of this approach\n",
    "- May not be better for smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag tokenized_tweets with an index for identification\n",
    "tagged_train_data = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized_train_data)]\n",
    "\n",
    "# Initialize and train a Doc2Vec vectorizer\n",
    "vectorizer = Doc2Vec(tagged_train_data, vector_size=50, window=2, min_count=1, workers=4, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer vectors for testing set\n",
    "test_vectors = np.array([vectorizer.infer_vector(doc_tokens) for doc_tokens in tokenized_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array([vectorizer.dv[i] for i in range(len(tagged_train_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- Many potentially good models, not clear which one will work best\n",
    "- Trying 5\n",
    "    - Logistic Regression\n",
    "    - Multinomial Naive Bayes\n",
    "    - Support Vector Machines\n",
    "    - Random Forest Classifier\n",
    "    - LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "- Performs well with binomial classification tasks\n",
    "- Interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_lr = logreg.predict(X_train_tfidf)\n",
    "y_test_preds_lr = logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      2821\n",
      "           1       0.93      0.87      0.90      2365\n",
      "\n",
      "    accuracy                           0.91      5186\n",
      "   macro avg       0.91      0.90      0.91      5186\n",
      "weighted avg       0.91      0.91      0.91      5186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_preds_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Train Accuracy: 90.8%\n"
     ]
    }
   ],
   "source": [
    "print(f'LogReg Train Accuracy: {accuracy_score(y_train, y_preds_lr):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       709\n",
      "           1       0.87      0.80      0.83       588\n",
      "\n",
      "    accuracy                           0.85      1297\n",
      "   macro avg       0.85      0.85      0.85      1297\n",
      "weighted avg       0.85      0.85      0.85      1297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_preds_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Test Accuracy: 85.1%\n"
     ]
    }
   ],
   "source": [
    "print(f'LogReg Test Accuracy: {accuracy_score(y_test,y_test_preds_lr):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes\n",
    "- Good for multinomial classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I THINK THERE WERE SOME TYPOS IN THE MULTI NB SECTION, I FIXED<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_mnb = mnb.predict(X_train_tfidf)\n",
    "y_preds_test_mnb = mnb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2821\n",
      "           1       0.90      0.88      0.89      2365\n",
      "\n",
      "    accuracy                           0.90      5186\n",
      "   macro avg       0.90      0.90      0.90      5186\n",
      "weighted avg       0.90      0.90      0.90      5186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_preds_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Train Accuracy: 90.1%\n"
     ]
    }
   ],
   "source": [
    "print(f'MultinomialNB Train Accuracy: {accuracy_score(y_train, y_preds_mnb):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       709\n",
      "           1       0.82      0.82      0.82       588\n",
      "\n",
      "    accuracy                           0.84      1297\n",
      "   macro avg       0.83      0.83      0.83      1297\n",
      "weighted avg       0.83      0.84      0.83      1297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_test_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Test Accuracy: 83.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'MultinomialNB Test Accuracy: {accuracy_score(y_test, y_preds_test_mnb):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines\n",
    "- Typically performs better in image or text classification task\n",
    "- Not interpretable\n",
    "- May not work as well on data with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: I COMMENTED OUT INITIAL AND GRIDSEARCH CODE TO SPEED UP THE MODEL, WE CAN UNCOMMENT FOR THE FINAL AND LET IT RUN<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(random_state=42)\n",
    "# svc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds_svc = svc.predict(X_train_tfidf)\n",
    "# y_preds_test_svc = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_train, y_preds_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_preds_test_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#           'degree':[2,3,4],\n",
    "#           'shrinking':[True,False],\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_grid = GridSearchCV(svc, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# svc_grid.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(svc_grid.best_estimator_)\n",
    "# print(svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=2, kernel=&#x27;poly&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=2, kernel=&#x27;poly&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(degree=2, kernel='poly', random_state=42)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_tuned = SVC(degree=2, kernel='poly', shrinking=True, random_state=42)\n",
    "svc_tuned.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_svc = svc_tuned.predict(X_train_tfidf)\n",
    "y_preds_test_svc = svc_tuned.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2821\n",
      "           1       0.99      0.99      0.99      2365\n",
      "\n",
      "    accuracy                           0.99      5186\n",
      "   macro avg       0.99      0.99      0.99      5186\n",
      "weighted avg       0.99      0.99      0.99      5186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_preds_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy: 99.4%\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Train Accuracy: {accuracy_score(y_train, y_preds_svc):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88       709\n",
      "           1       0.88      0.79      0.83       588\n",
      "\n",
      "    accuracy                           0.86      1297\n",
      "   macro avg       0.86      0.85      0.85      1297\n",
      "weighted avg       0.86      0.86      0.86      1297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_test_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 85.7%\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Test Accuracy: {accuracy_score(y_test, y_preds_test_svc):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "- Might be better for non-linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier()\n",
    "# rf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds_rf = rf.predict(X_train_tfidf)\n",
    "# y_preds_test_rf = rf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_train, y_preds_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_preds_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_params = {'n_estimators':[10, 50, 100],\n",
    "#              'criterion':['gini','entropy','log_loss'],\n",
    "#              'max_depth':[5,10,20]\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid = GridSearchCV(rf, param_grid=rf_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rf_grid.best_estimator_)\n",
    "# print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=20, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=20, random_state=42)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(criterion='log_loss', max_depth=20, n_estimators=100, random_state=42)\n",
    "rf2.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rf2 = rf2.predict(X_train_tfidf)\n",
    "y_preds_test_rf2 = rf2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85      2821\n",
      "           1       0.93      0.66      0.77      2365\n",
      "\n",
      "    accuracy                           0.82      5186\n",
      "   macro avg       0.85      0.81      0.81      5186\n",
      "weighted avg       0.84      0.82      0.82      5186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_preds_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 82.2%\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Train Accuracy: {accuracy_score(y_train, y_preds_rf2):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       709\n",
      "           1       0.87      0.63      0.73       588\n",
      "\n",
      "    accuracy                           0.79      1297\n",
      "   macro avg       0.81      0.78      0.78      1297\n",
      "weighted avg       0.81      0.79      0.78      1297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_test_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 79.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Test Accuracy: {accuracy_score(y_test, y_preds_test_rf2):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "- Performs very well on very large datasets\n",
    "- Excels at detecting complex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(vectors, label=y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',  # Traditional Gradient Boosting Decision Tree\n",
    "          'objective': 'binary',    # Binary classification\n",
    "          'metric': ['binary_error'],  # Evaluation metrics\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.5,\n",
    "          'max_bin': 100,\n",
    "          'num_leaves': 20,         # Number of leaves in full trees\n",
    "          'learning_rate': 0.05,    # Learning rate\n",
    "          'feature_fraction': 0.9,  # Fraction of features to be used at each iteration\n",
    "          'bagging_fraction': 0.8,  # Fraction of data to be used for each iteration\n",
    "          'bagging_freq': 5,        # Frequency for bagging\n",
    "          'verbose': 1              # Verbose output in the terminal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2365, number of negative: 2821\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5000\n",
      "[LightGBM] [Info] Number of data points in the train set: 5186, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.456035 -> initscore=-0.176313\n",
      "[LightGBM] [Info] Start training from score -0.176313\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_round = 100  # Number of boosting rounds\n",
    "lgb_model = lgb.train(params, train_data, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      2821\n",
      "           1       0.86      0.84      0.85      2365\n",
      "\n",
      "    accuracy                           0.86      5186\n",
      "   macro avg       0.86      0.86      0.86      5186\n",
      "weighted avg       0.86      0.86      0.86      5186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and convert to binary\n",
    "y_preds_lgb = lgb_model.predict(vectors, num_iteration=lgb_model.best_iteration)\n",
    "y_preds_binary = [1 if prob > 0.5 else 0 for prob in y_preds_lgb]\n",
    "\n",
    "print(classification_report(y_train, y_preds_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Train Accuracy: 86.3%\n"
     ]
    }
   ],
   "source": [
    "print(f'LightGBM Train Accuracy: {accuracy_score(y_train, y_preds_binary):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73       709\n",
      "           1       0.67      0.71      0.69       588\n",
      "\n",
      "    accuracy                           0.71      1297\n",
      "   macro avg       0.71      0.71      0.71      1297\n",
      "weighted avg       0.71      0.71      0.71      1297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_preds_test_lgb = lgb_model.predict(test_vectors, num_iteration=lgb_model.best_iteration)\n",
    "y_preds_test_binary = [1 if prob > 0.5 else 0 for prob in y_preds_test_lgb]\n",
    "\n",
    "print(classification_report(y_test, y_preds_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Test Accuracy: 70.9%\n"
     ]
    }
   ],
   "source": [
    "print(f'LightGBM Test Accuracy: {accuracy_score(y_test, y_preds_test_binary):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Conclusion\n",
    "- LightGBM is bad\n",
    "- SVM seems badly overfit\n",
    "- Multinomial NB and Random Forest are okay\n",
    "- Logistic Regression is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">NOTE: EVERYTHING BELOW IS NEW<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize vision pro tweets\n",
    "- Use the *fitted* vectorizer to vectorize the Vision Pro tweets\n",
    "- The vectorizer must be limited to only the vocabulary seen in the initial dataset\n",
    "- Words not in the initial dataset will be dropped, which will limit the model's accuracy on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized tweets back into strings for TfidfVectorizer\n",
    "df_english['tweet_join'] = df_english['tweet'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the new tweets with the fitted vectorizer\n",
    "vp_vectored = tfidf_vectorizer.fit_transform(df_english['tweet_join'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "vp_preds = logreg.predict(vp_vectored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgBUlEQVR4nO3dfZxWdZ3/8deb4f5ORG4abhRM1NC8RcRM8zYw23Rb3VBLdpcWcy0rN0tq020Ns/zVrpaQpCZuqeGqQZa3qKml3KiIihIociMIwojcwzDz+f1xncELnLnmumSuuWau834+HudxnfO9vuec75lhPnzvzjmKCMzM0qZNqQtgZlYKDn5mlkoOfmaWSg5+ZpZKDn5mlkptS12AbL16VsSgge1KXQwrwN/mdS51EawAW9nE9timPTnGyJO7xNqqmrzyPjdv20MRMWpPzlcsLSr4DRrYjlkPDSx1MawAI/sdUeoiWAFmxow9PsbaqhpmPbRvXnkrKhf22uMTFkmLCn5m1vIFUEttqYuxxxz8zKwgQVAd+TV7WzIHPzMrmGt+ZpY6QVBTBrfFOviZWcFqcfAzs5QJoMbBz8zSyDU/M0udAKrd52dmaROEm71mlkIBNa0/9jn4mVlhMnd4tH4OfmZWIFHDHj0boUVw8DOzgmQGPBz8zCxlMvP8HPzMLIVqXfMzs7Qpl5qfH2NvZgUJRA1t8lpykXSQpLlZy3pJ35DUU9IjkhYmn3tn7TNe0iJJCySNzEo/WtJLyXc3SGo0Ojv4mVnBakN5LblExIKIOCIijgCOBjYD9wFXADMiYggwI9lG0lBgNHAIMAqYKKkiOdwkYBwwJFkafXS+g5+ZFSQQ26Mir6UApwKvR8QS4CxgSpI+BTg7WT8LuCsitkXEYmARMFxSJdA9Ip6JiABuz9qnQe7zM7OCZCY5511v6iVpTtb25IiYXE++0cCdyXrfiFgJEBErJfVJ0vsDz2btszxJq07Wd0/PycHPzApWwIDHmogYliuDpPbA54DxjRyrvpNGjvScHPzMrCARoiaatMfsDOD5iFiVbK+SVJnU+iqB1Un6ciD79Y4DgBVJ+oB60nNyn5+ZFawW5bXk6Tzeb/ICTAfGJOtjgGlZ6aMldZA0mMzAxqykibxB0ohklPfCrH0a5JqfmRUkM+DRNKFDUmfgdOCirORrgamSxgJLgXMBIuIVSVOB+cAO4JKIna+Ruxi4DegEPJAsOTn4mVlBChzwyH2siM3APrulrSUz+ltf/gnAhHrS5wCHFnJuBz8zK1iNb28zs7Spu8OjtXPwM7OC1TbtaG9JOPiZWUEyDzZw8DOzlAlEdWG3rrVIDn5mVpAImnqSc0k4+JlZgQqawNxiOfiZWUEC1/zMLKU84GFmqRM0/qDS1sDBz8wKknl1ZesPHa3/Csysmfml5WaWQoHv8DCzlHLNz8xSJ0Ku+ZlZ+mQGPHx7m5mlTpO/w6MkHPzMrCCZAQ/3+ZlZCvkODzNLHd/hYWap1VQvMColBz8zK0gEVNc6+JlZymSavQ5+ZpZCvsMjpZYt6sA1Xxm0c/vtpe350uVv8/l/fYdpt/Ri+q970aZtcOyp6/ny91eyvqqCq8cN4m9zO3P6P1bx1Wve2rnv5f9wAFWr2tK+YwDwo7tep0evHc19SWXvsp8t5djTNrBuTVsuOuUgAL78/RWMOH091dvFyiXt+ek392XT+gqOOnED//LdlbRtF+yoFr+6upIX/9KNDp1q+d5Nb9Jv0HZqa+DZR7pz6zX9Snxlzc9TXfIgaRRwPVAB3BwR1xbzfM1l4AHbmPToAgBqauCCow7h+DPWMfcvXfnrQ3sxacYC2ncI1q3J/HjbdwzGXP42by7oyJuvdfzA8b5z4xIOPHxLs15D2jz8u55M/3UvLr9+2c6055/sxq3XVFJbI8Z+bwWjv7aKWyb0472qCq4cM5iqVe3Y76AtXHPHG1xw9CEA3PPLPrz41660bVfLj6e+wbCT1zPn8e6luqwSabpmr6QewM3AoWTi6r8AC4DfAYOAN4F/jIh3k/zjgbFADXBpRDyUpB8N3AZ0Av4EfD0iIte5i9Zwl1QB3AicAQwFzpM0tFjnK5W5T3Wjcr9t9B1Qzf2378MXvrqK9h0yP/O6GlzHzrUceuymnenW/F6e2ZUN7+76f/3zf+5GbU2mBvPqc13oVVkNwOsvd6ZqVTsAlizoSPsOQbv2tWzb0oYX/9oVgB3VbVj4Uid6J/ukTW3yHo/GljxcDzwYEQcDhwOvAlcAMyJiCDAj2SaJH6OBQ4BRwMQkzgBMAsYBQ5JlVGMnLmav5XBgUUS8ERHbgbuAs4p4vpJ4YloPTjp7HQBvvd6Rl2d25dIzh/Ctzx/Agrmd8jrGT7+5LxefdhC//e++5P6/yopl5HlVzH7sgzW4T575Hq+/0onq7bv+qXTpXsOI09fzwtNdm6uILUZmtLciryUXSd2BE4FbMseN7RGxjkycmJJkmwKcnayfBdwVEdsiYjGwCBguqRLoHhHPJLW927P2aVAxg19/YFnW9vIkbReSxkmaI2nOO2trilicple9XTz78F6c+HfrgEwTeON7FVx//0K+/P0VTLhoUKPB7Du/WMJNjy3gp79fyMszu/Do/+1d/ILbLs67dBU1O+Cxe3vskr7fgVsZ+72VXP/tAbukt6kIxk9cwrRbevH20g7NWNKWoW6Scz4L0Kvu7ztZxmUdan/gHeDXkl6QdLOkLkDfiFgJkHz2SfI3FFP6J+u7p+dUzOBXX533A6EgIiZHxLCIGNZ7n9b1pIjZj3XjgI9vZu/emeZtr8pqjv/Me0hw8JGbadMG3qvKfU11Ta3OXWs5+e/XseCFzkUvt73vtHOrGH7aen781f3I/ifbq3I7V96ymOu+vi8rl+wa4L5x3TLeWtyB+27u3cylbTkKaPauqfv7TpbJWYdpCxwFTIqII4FNJE3cBjQUU/KKNbsrZvBbDgzM2h4ArCji+ZrdE7/fe2eTF+ATo95jbtIMWv56B6q3i716NlybrdkB763NBMcd1TDz0e4MOnhrUcts7xt20nr+8ZLV/Oc/DWbblvf/FLp0r+Hq2xfz6x9VMn92l132GfPtlXTpVssvr0zfKG+dutHePGt+uSwHlkfEzGT7/8gEw1VJU5bkc3VW/vpiyvJkfff0nIo52jsbGCJpMPAWmY7K84t4vma1dbN4/qlufP0n79fCR46u4meXDWTcyQfRrl1w+fVLUfL7v3D4UDZtbMOO7eKZh/bimjtfp++Aar57/kep2SFqauCoEzZyxgVrS3RF5e2KiUs47LiN7NVzB7+ZM5///WlfRn91Ne06BD/63esAvPZcF264YgCf++c19Bu8nfO/uYrzv7kKgPGj96dd++D8b6xm6cIO3Pjw3wCY/utePHjHPiW7rlJpitHeiHhb0jJJB0XEAuBUYH6yjAGuTT6nJbtMB+6Q9DOgH5mBjVkRUSNpg6QRwEzgQuDnjZ1fjYwG7xFJnwH+h8xUl1sjYkKu/MMO7xizHhqYK4u1MCP7HVHqIlgBZsYM1kfVHk3S2/vgPnHKrefklffe4yc9FxHDGvpe0hFkprq0B94A/plMi3QqsC+wFDg3IqqS/N8jMx1mB/CNiHggSR/G+1NdHgC+1thUl6LO84uIP5GZc2NmZaSpJjlHxFygvuB4agP5JwAfqERFxBwycwXz5js8zKwgvsPDzFLLwc/MUscPMzWz1Mrz1rUWzcHPzAoSATv8MFMzSyM3e80sddznZ2apFQ5+ZpZGHvAws9SJcJ+fmaWSqPFor5mlkfv8zCx1fG+vmaVTUBbvmnHwM7OCebTXzFInPOBhZmnlZq+ZpZJHe80sdSIc/MwspTzVxcxSyX1+ZpY6gaj1aK+ZpVEZVPwc/MysQB7wMLPUKoOqX+tvuJtZs4tQXktjJL0p6SVJcyXNSdJ6SnpE0sLkc++s/OMlLZK0QNLIrPSjk+MsknSDpEZP3mDNT9LPyRHfI+LSRq/MzMpOALW1TdrsPTki1mRtXwHMiIhrJV2RbH9H0lBgNHAI0A94VNKBEVEDTALGAc8CfwJGAQ/kOmmuZu+cD30pZla+Aihun99ZwEnJ+hTgCeA7SfpdEbENWCxpETBc0ptA94h4BkDS7cDZfNjgFxFTsrcldYmITR/iQsyszBQwz69XXXM2MTkiJmcfCnhYUgA3Jd/1jYiVmfPESkl9krz9ydTs6ixP0qqT9d3Tc2p0wEPSccAtQFdgX0mHAxdFxL81tq+Zlan8g9+aiBiW4/vjI2JFEuAekfRajrz1VTcjR3pO+Qx4/A8wElgLEBEvAifmsZ+ZlaX8BjvyGfCIiBXJ52rgPmA4sEpSJUDyuTrJvhwYmLX7AGBFkj6gnvSc8hrtjYhluyXV5LOfmZWpyHPJQVIXSd3q1oFPAy8D04ExSbYxwLRkfTowWlIHSYOBIcCspIm8QdKIZJT3wqx9GpTPPL9lkj4BhKT2wKXAq3nsZ2blKCCaZrS3L3BfMiulLXBHRDwoaTYwVdJYYClwLkBEvCJpKjAf2AFckoz0AlwM3AZ0IjPQkXOwo+6EjfkKcD2ZDsS3gIeAS/K9OjMrR3se/CLiDeDwetLXAqc2sM8EYEI96XOAQws5f6PBL5l/c0EhBzWzMpeGOzwk7S/pD5LekbRa0jRJ+zdH4cyshWqCPr9Sy2fA4w5gKlBJZlb13cCdxSyUmbVgdZOc81lasHyCnyLifyNiR7L8hhYf082smCLyW1qyXPf29kxWH0/ur7uLTND7AvDHZiibmbVUTXtvb0nkGvB4jl1nT1+U9V0AVxerUGbWsqmF1+rykeve3sHNWRAzayVawWBGPvJ6mKmkQ4GhQMe6tIi4vViFMrOWrOUPZuQjnwcbXEXm8TJDyTwn6wzgacDBzyytyqDml89o7zlkZlu/HRH/TGZGdoeilsrMWrbaPJcWLJ9m75aIqJW0Q1J3Mk9Y8CRns7Qq/sNMm0U+wW+OpB7Ar8iMAG8EZhWzUGbWspX1aG+drIeW/lLSg2QeFz2vuMUysxatnIOfpKNyfRcRzxenSGZmxZer5vfTHN8FcEoTl4W/vb4Pnz5nTOMZrcXYfE7HxjNZi1H76LONZ8pDWTd7I+Lk5iyImbUSQdnf3mZmVr9yrvmZmTWkrJu9ZmYNKoPgl8+TnCXpi5KuTLb3lTS8+EUzsxYrJU9ynggcB5yXbG8AbixaicysRVPkv7Rk+TR7j42IoyS9ABAR7yavsDSztErJaG+1pAqSSqyk3rT4W5bNrJhaeq0uH/k0e28A7gP6SJpA5nFW1xS1VGbWspVBn18+9/b+VtJzZB5rJeDsiHi16CUzs5apFfTn5SOf0d59gc3AH4DpwKYkzczSqglrfpIqJL0g6f5ku6ekRyQtTD73zso7XtIiSQskjcxKP1rSS8l3N0hqtFMyn2bvH4H7k88ZwBvAA/ldlpmVI9Xmt+Tp60B2a/IKYEZEDCETc64AkDQUGA0cAowCJibjEQCTgHHAkGQZ1dhJGw1+EfHxiDgs+RwCDCfT72dmtkckDQDOBG7OSj4LmJKsTwHOzkq/KyK2RcRiYBEwXFIlmUftPRMRQeYVG2fTiHxqfrtIHmV1TKH7mVkZyb/Z20vSnKxl3G5H+h/g2+w6g6RvRKwESD77JOn9gWVZ+ZYnaf2T9d3Tc8rnBUaXZW22AY4C3mlsPzMrU4UNeKyJiGH1fSHps8DqiHhO0kl5HKu+frzIkZ5TPvP8umWt7yDT93dPHvuZWblqmtHe44HPSfoMmdfidpf0G2CVpMqIWJk0aVcn+ZcDA7P2HwCsSNIH1JOeU85mb9KZ2DUifpAsEyLitxGxNd+rM7My1ASjvRExPiIGRMQgMgMZj0XEF8nMKql7qvEYYFqyPh0YLamDpMFkBjZmJU3jDZJGJKO8F2bt06Bcj7FvGxE7cj3O3szSRxQ0kvthXAtMlTQWWAqcCxARr0iaCswn0wq9JCJqkn0uBm4DOpGZjdLojJRczd5ZZPr35kqaDtwNbKr7MiLuLfCCzKwcFGGSc0Q8ATyRrK8lc1NFffkmABPqSZ8DHFrIOfPp8+sJrCXzzo66zsUAHPzM0qoM7vDIFfz6JCO9L/PBEZUyuHQz+9DKIALkCn4VQFc+5DCymZWvcri3N1fwWxkR/9VsJTGz1qPMg1/rf1qhmTW9KPpob7PIFfzqHW0xMyvrml9EVDVnQcys9Sj3Pj8zs/o5+JlZ6rSCR9Tnw8HPzAoi3Ow1s5Ry8DOzdHLwM7NUcvAzs9Qpk1dXOviZWeEc/Mwsjcr99jYzs3q52Wtm6eNJzmaWWg5+ZpY2vsPDzFJLta0/+jn4mVlh3OdnZmnlZq+ZpZODn5mlUTnU/NqUugBm1gpFnksOkjpKmiXpRUmvSPpBkt5T0iOSFiafe2ftM17SIkkLJI3MSj9a0kvJdzdIavQFbA5+ZlaY5O1t+SyN2AacEhGHA0cAoySNAK4AZkTEEGBGso2kocBo4BBgFDBRUkVyrEnAOGBIsoxq7OQOfmZWkLp5fvksuUTGxmSzXbIEcBYwJUmfApydrJ8F3BUR2yJiMbAIGC6pEugeEc9ERAC3Z+3TIAc/MytcRH4L9JI0J2sZl30YSRWS5gKrgUciYibQNyJWZk4TK4E+Sfb+wLKs3Zcnaf2T9d3Tc/KAh5kVrIABjzURMayhLyOiBjhCUg/gPkmH5jptfYfIkZ6Tg9+H0HufTVz+tafp2WMrtQF/euRAfv+njzFm9Ascd8wyolasW9+R635xPFXvduaow1Yw9oLnadu2lh072vCr/z2auS9X7nLMH3znMSr7bmTcZZ8r0VWVtz49NvIfX3qcnt22ECGm//Vg7v7zxzmg31q+9YWn6NShmreruvGD209h89b2dO+8lR+OfYSD932HB2YeyH//3yc/cMxr//VB+u2zgQuvPbcEV1RCRZjkHBHrJD1Bpq9ulaTKiFiZNGlXJ9mWAwOzdhsArEjSB9STnlPRgp+kW4HPAqsjIlc0b3VqasTkKcNYtHgfOnWs5saf3M/z8yq5e9ohTLnrSADO/syrfPHcedwweQTvbejA9689hap3OzNo4Ltc8x+Pcv5F7//BHH/sErZs9f9DxVRT24Zf3Hccf1vei04dtnPr5fcxe8EAvnPek9w47VjmLurHmSNe4/xTXuTmPx3D9h0V3PzHYxhcWcX+lVUfON6Jhy1my7Z2JbiSlqEpnucnqTdQnQS+TsBpwI+B6cAY4Nrkc1qyy3TgDkk/A/qRGdiYFRE1kjYkgyUzgQuBnzd2/mL2+d1GHiMurVHVus4sWrwPAFu2tmPpW3vRq+dmNm9pvzNPxw47ki4PeH3xPlS92xmAN5f1oH37Gtq1rcnk61jNP3x2Pnfcc1jzXkTKrF3fmb8t7wXAlm3teXNVD3rttYl9+65j7qJMLXz2awP41BGLAdi6vR3z3vgI26srPnCsTu2rGX3yPKY8fFTzXUAL00SjvZXA45LmAbPJ9PndTybonS5pIXB6sk1EvAJMBeYDDwKXJM1mgIuBm8kMgrwOPNDYyYtW3YiIJyUNKtbxW4q+vTdywKAqXluY+cP6p/Ne4PRPvc6mze25/D8//YH8J4xYyqLFPanekfmj+qfRc7nnD4ewbZtrfs3lIz03cGD/Ncxf0oc3Vvbkkx9fwtMvDeLkI9+gb49Nje7/5TNnc9fjh7F1e0p/ZwE7/2ffk8NEzAOOrCd9LXBqA/tMACbUkz4HKKiFWfLRXknj6kaCqnc0/g+vJenYsZorv/UEk247Zmet77Y7j+SCr5zDY08N5nOjXtsl/34D1jH2i89x/U3HAbD/oCr6fWQDf5m1b7OXPa06ta9mwthHuP7eT7B5a3t+9NtP8fkTXuGWy++lc4dqqmty/0kc0H8NA3qv58l5g5upxC1TU0x1KbWSB7+ImBwRwyJiWLu2XUpdnLxVVNRy5bee4LGn9ucvM/f7wPePPTWYE0Ys3bndq+cmrvr24/zk559k5apuAAw98B2G7L+W2yfew89++CD9K9dz3Q8earZrSJuKNrX8cOwjPDzngJ3Ba+nqHlw28UzGXvd5Hn3uo7y1pnvOYxw6eDUHDVzD3VfdwcRvTGdgn/f4+df+0BzFb1ma4A6PUktpvX1PBZf9219ZurwH99w/dGdqv4+sZ8XbmT+e445ZxrK3MutdOm/n6u8+xq2/PYr5C/rszH//wwdx/8MHAZnm89XjH+Pyq0ZixRCMP//PLFnVg989/n7/ao+uW1i3sRNSMGbkC0z7y8dyHuX3Tw/l909nfucf6bmBn4x7kK/9/O+KWvKWxg8zTbFDDl7N6Z96gzeW9GDSdZn/9W+940hGnbqIgf3WUxuw+p2uXD95BABnnfEa/T+ygQvOmccF58wDYPzVp7FufaeSXUPaHLb/KkYNX8iit3ry62/fA8BN9x/DwN7v8fkT5gPw5xcH8cdnD9q5z91X3UGXjtW0bVvDCYct4bKJn+HNt/eu9/ipElEWDzNVNEHHZb0Hlu4ETgJ6AauAqyLillz7dO/aP4YfcXFRymPFsblfx1IXwQow79Hr2Vi1rNGb/nPp1mNAHHni1/PK+9Qfvv1crknOpVTM0d7zinVsMystN3vNLH0CKINmr4OfmRWu9cc+Bz8zK5ybvWaWSuUw2uvgZ2aFaQUTmPPh4GdmBclMcm790c/Bz8wK1wSPtCo1Bz8zK5hrfmaWPu7zM7N0Ko97ex38zKxwbvaaWepE07zDo9Qc/MyscK75mVkqtf7Y5+BnZoVTbetv9zr4mVlhAk9yNrP0EeFJzmaWUg5+ZpZKZRD8Sv7eXjNrZer6/PJZcpA0UNLjkl6V9IqkryfpPSU9Imlh8rl31j7jJS2StEDSyKz0oyW9lHx3g6RGX9Lk4GdmBVNtbV5LI3YA/x4RHwNGAJdIGgpcAcyIiCHAjGSb5LvRwCHAKGCipIrkWJOAccCQZBnV2Mkd/MysQJFp9uaz5DpKxMqIeD5Z3wC8CvQHzgKmJNmmAGcn62cBd0XEtohYDCwChkuqBLpHxDOReRfv7Vn7NMh9fmZWmKCQPr9ekuZkbU+OiMm7Z5I0CDgSmAn0jYiVkAmQkvok2foDz2bttjxJq07Wd0/PycHPzAqX/zy/NY29tFxSV+Ae4BsRsT5Hd119X0SO9Jzc7DWzgikir6XR40jtyAS+30bEvUnyqqQpS/K5OklfDgzM2n0AsCJJH1BPek4OfmZWuCbo80tGZG8BXo2In2V9NR0Yk6yPAaZlpY+W1EHSYDIDG7OSJvIGSSOSY16YtU+D3Ow1s8JEQE2T3N92PPAl4CVJc5O07wLXAlMljQWWAudmThuvSJoKzCczUnxJRNQk+10M3AZ0Ah5Ilpwc/MyscE0wyTkinqb+/jqAUxvYZwIwoZ70OcChhZzfwc/MClcGd3g4+JlZYQLwOzzMLH0CovU/08rBz8wKEzTVgEdJOfiZWeHc52dmqeTgZ2bp0/gE5tbAwc/MChOAX2BkZqnkmp+ZpU+T3d5WUg5+ZlaYgPA8PzNLJd/hYWap5D4/M0udCI/2mllKueZnZukTRE1N49laOAc/MyuMH2llZqnlqS5mljYBhGt+ZpY64YeZmllKlcOAh6IFDVlLegdYUupyFEEvYE2pC2EFKdff2X4R0XtPDiDpQTI/n3ysiYhRe3K+YmlRwa9cSZoTEcNKXQ7Ln39n5a9NqQtgZlYKDn5mlkoOfs1jcqkLYAXz76zMuc/PzFLJNT8zSyUHPzNLJQe/IpI0StICSYskXVHq8ljjJN0qabWkl0tdFisuB78ikVQB3AicAQwFzpM0tLSlsjzcBrTISbnWtBz8imc4sCgi3oiI7cBdwFklLpM1IiKeBKpKXQ4rPge/4ukPLMvaXp6kmVkL4OBXPKonzfOKzFoIB7/iWQ4MzNoeAKwoUVnMbDcOfsUzGxgiabCk9sBoYHqJy2RmCQe/IomIHcBXgYeAV4GpEfFKaUtljZF0J/AMcJCk5ZLGlrpMVhy+vc3MUsk1PzNLJQc/M0slBz8zSyUHPzNLJQc/M0slB79WRFKNpLmSXpZ0t6TOe3Cs2ySdk6zfnOuhC5JOkvSJD3GONyV94C1fDaXvlmdjgef6T0nfKrSMll4Ofq3Llog4IiIOBbYDX8n+MnmSTMEi4ssRMT9HlpOAgoOfWUvm4Nd6PQUckNTKHpd0B/CSpApJ10maLWmepIsAlPELSfMl/RHoU3cgSU9IGpasj5L0vKQXJc2QNIhMkP1mUus8QVJvSfck55gt6fhk330kPSzpBUk3Uf/9zbuQ9HtJz0l6RdK43b77aVKWGZJ6J2kflfRgss9Tkg5ukp+mpU7bUhfACiepLZnnBD6YJA0HDo2IxUkAeS8ijpHUAfiLpIeBI4GDgI8DfYH5wK27Hbc38CvgxORYPSOiStIvgY0R8f+SfHcA/x0RT0val8xdLB8DrgKejoj/knQmsEswa8C/JOfoBMyWdE9ErAW6AM9HxL9LujI59lfJvFjoKxGxUNKxwETglA/xY7SUc/BrXTpJmpusPwXcQqY5OisiFifpnwYOq+vPA/YChgAnAndGRA2wQtJj9Rx/BPBk3bEioqHn2p0GDJV2Vuy6S+qWnOPzyb5/lPRuHtd0qaS/T9YHJmVdC9QCv0vSfwPcK6lrcr13Z527Qx7nMPsAB7/WZUtEHJGdkASBTdlJwNci4qHd8n2Gxh+ppTzyQKa75LiI2FJPWfK+X1LSSWQC6XERsVnSE0DHBrJHct51u/8MzD4M9/mVn4eAiyW1A5B0oKQuwJPA6KRPsBI4uZ59nwE+JWlwsm/PJH0D0C0r38NkmqAk+Y5IVp8ELkjSzgD2bqSsewHvJoHvYDI1zzptgLra6/lkmtPrgcWSzk3OIUmHN3IOs3o5+JWfm8n05z2fvITnJjI1/PuAhcBLwCTgz7vvGBHvkOmnu1fSi7zf7PwD8Pd1Ax7ApcCwZEBlPu+POv8AOFHS82Sa30sbKeuDQFtJ84CrgWezvtsEHCLpOTJ9ev+VpF8AjE3K9wp+NYB9SH6qi5mlkmt+ZpZKDn5mlkoOfmaWSg5+ZpZKDn5mlkoOfmaWSg5+ZpZK/x+ogG+kT3TkKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(df_english['sentiment'], vp_preds)\n",
    "ConfusionMatrixDisplay(cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81      8837\n",
      "           1       0.70      0.56      0.62      5238\n",
      "\n",
      "    accuracy                           0.75     14075\n",
      "   macro avg       0.74      0.71      0.72     14075\n",
      "weighted avg       0.74      0.75      0.74     14075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_english['sentiment'], vp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Accuracy vs VADER: 74.8%\n"
     ]
    }
   ],
   "source": [
    "print(f'LogReg Accuracy vs VADER: {accuracy_score(df_english[\"sentiment\"], vp_preds):.1%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
